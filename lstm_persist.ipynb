{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from torchnlp.datasets import iwslt_dataset\n",
    "from torchnlp.word_to_vector import GloVe\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 196884\n",
      "Dev: 993\n",
      "Test: 1305\n"
     ]
    }
   ],
   "source": [
    "train_raw = [sentence['en'] for sentence in iwslt_dataset(train=True)]\n",
    "dev_raw = [sentence['en'] for sentence in iwslt_dataset(dev=True)]\n",
    "test_raw = [sentence['en'] for sentence in iwslt_dataset(test=True)]\n",
    "print(\"Train:\", len(train_raw))\n",
    "print(\"Dev:\", len(dev_raw))\n",
    "print(\"Test:\", len(test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the train data\n",
      "Tokenizing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc046390fe9b4f478c5d9c558ba671d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196884.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecd1cb1185545c0bb72baee6e692fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating labels:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3383f285d384fafb37d8a0360b1eb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get word vector weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9aa9e18d624faeb57dbbc173e39c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=196880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting labels to tensor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1c0aa81e974de2b06346110afabf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3483278.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing samples of the dataset\n",
      "['<pad>', '<pad>', 'David', 'Gallo', 'This'] ('o', True)\n",
      "['<pad>', 'David', 'Gallo', 'This', 'is'] ('o', True)\n",
      "['David', 'Gallo', 'This', 'is', 'Bill'] ('o', True)\n",
      "['Gallo', 'This', 'is', 'Bill', 'Lange'] ('o', False)\n",
      "['This', 'is', 'Bill', 'Lange', 'I'] ('o', True)\n",
      "['is', 'Bill', 'Lange', 'I', \"'m\"] ('.', True)\n",
      "['Bill', 'Lange', 'I', \"'m\", 'Dave'] ('o', True)\n",
      "['Lange', 'I', \"'m\", 'Dave', 'Gallo'] ('o', False)\n",
      "['I', \"'m\", 'Dave', 'Gallo', '<pad>'] ('o', True)\n",
      "[\"'m\", 'Dave', 'Gallo', '<pad>', '<pad>'] ('.', True)\n",
      "['<pad>', '<pad>', 'And', 'we', \"'re\"] ('o', True)\n",
      "['<pad>', 'And', 'we', \"'re\", 'going'] ('o', False)\n",
      "['And', 'we', \"'re\", 'going', 'to'] ('o', False)\n",
      "['we', \"'re\", 'going', 'to', 'tell'] ('o', False)\n",
      "[\"'re\", 'going', 'to', 'tell', 'you'] ('o', False)\n",
      "Total number of samples:  3483136\n",
      "Preprocessing the dev data\n",
      "Tokenizing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7c6e87eb0240219c983c9df17cc0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=993.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ac198ac78d4559bd8bf80c88f8aa39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=993.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating labels:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a24f0fbfe049c9bc618b58dff55e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=993.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get word vector weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2edac2cb3334b89808a32d6d4df4e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=993.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting labels to tensor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c23a744570419693cdf2cd62c2f5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18302.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing samples of the dataset\n",
      "['<pad>', '<pad>', 'When', 'I', 'was'] ('o', True)\n",
      "['<pad>', 'When', 'I', 'was', '11'] ('o', True)\n",
      "['When', 'I', 'was', '11', 'I'] ('o', False)\n",
      "['I', 'was', '11', 'I', 'remember'] (',', False)\n",
      "['was', '11', 'I', 'remember', 'waking'] ('o', True)\n",
      "['11', 'I', 'remember', 'waking', 'up'] ('o', False)\n",
      "['I', 'remember', 'waking', 'up', 'one'] ('o', False)\n",
      "['remember', 'waking', 'up', 'one', 'morning'] ('o', False)\n",
      "['waking', 'up', 'one', 'morning', 'to'] ('o', False)\n",
      "['up', 'one', 'morning', 'to', 'the'] ('o', False)\n",
      "['one', 'morning', 'to', 'the', 'sound'] ('o', False)\n",
      "['morning', 'to', 'the', 'sound', 'of'] ('o', False)\n",
      "['to', 'the', 'sound', 'of', 'joy'] ('o', False)\n",
      "['the', 'sound', 'of', 'joy', 'in'] ('o', False)\n",
      "['sound', 'of', 'joy', 'in', 'my'] ('o', False)\n",
      "Total number of samples:  18176\n",
      "Preprocessing the test data\n",
      "Tokenizing:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f04d380965243869c346f43cde8ce90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1305.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f7346ec82b4012baae00881fa40572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1305.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating labels:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1fcf465f7f417b81bf8ad226759d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1305.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get word vector weights\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02345863dbca48e08d8c7bd2eb19c771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1305.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting labels to tensor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfacbdf6b27492aa79d348786807c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21793.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing samples of the dataset\n",
      "['<pad>', '<pad>', 'When', 'I', 'was'] ('o', True)\n",
      "['<pad>', 'When', 'I', 'was', 'in'] ('o', True)\n",
      "['When', 'I', 'was', 'in', 'my'] ('o', False)\n",
      "['I', 'was', 'in', 'my', '20s'] ('o', False)\n",
      "['was', 'in', 'my', '20s', 'I'] ('o', False)\n",
      "['in', 'my', '20s', 'I', 'saw'] (',', False)\n",
      "['my', '20s', 'I', 'saw', 'my'] ('o', True)\n",
      "['20s', 'I', 'saw', 'my', 'very'] ('o', False)\n",
      "['I', 'saw', 'my', 'very', 'first'] ('o', False)\n",
      "['saw', 'my', 'very', 'first', 'psychotherapy'] ('o', False)\n",
      "['my', 'very', 'first', 'psychotherapy', 'client'] ('o', False)\n",
      "['very', 'first', 'psychotherapy', 'client', '<pad>'] ('o', False)\n",
      "['first', 'psychotherapy', 'client', '<pad>', '<pad>'] ('.', False)\n",
      "['<pad>', '<pad>', 'I', 'was', 'a'] ('o', True)\n",
      "['<pad>', 'I', 'was', 'a', 'Ph.D.'] ('o', False)\n",
      "Total number of samples:  21760\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing the train data\")\n",
    "train_x, train_y = preprocess_data(train_raw, vectors)\n",
    "print(\"Preprocessing the dev data\")\n",
    "dev_x, dev_y = preprocess_data(dev_raw, vectors)\n",
    "print(\"Preprocessing the test data\")\n",
    "test_x, test_y = preprocess_data(test_raw, vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import PuncDataset\n",
    "train_loader = DataLoader(PuncDataset(train_x, train_y), batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(PuncDataset(dev_x, dev_y), batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(PuncDataset(test_x, test_y), batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import PuncLstm\n",
    "\n",
    "model = PuncLstm(CLASSES, WINDOW_SIZE)\n",
    "model.to(device)\n",
    "criterions = [nn.CrossEntropyLoss(), nn.CrossEntropyLoss()]\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 52.57996456065494\n",
      "Training loss for capitalization: 20.38393548147198\n",
      "Validation accuracy: punctuation: 94.4762%, capitalization: 98.564%\n",
      "Find a new best model!\n",
      "----------------------------\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 42.90522576969511\n",
      "Training loss for capitalization: 14.358167224240166\n",
      "Validation accuracy: punctuation: 94.8118%, capitalization: 98.6301%\n",
      "Find a new best model!\n",
      "----------------------------\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 40.283745361394296\n",
      "Training loss for capitalization: 13.054546028309915\n",
      "Validation accuracy: punctuation: 95.0099%, capitalization: 98.6521%\n",
      "Find a new best model!\n",
      "----------------------------\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 38.489875822755565\n",
      "Training loss for capitalization: 12.089506015266966\n",
      "Validation accuracy: punctuation: 94.9439%, capitalization: 98.6851%\n",
      "----------------------------\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 37.042066068591815\n",
      "Training loss for capitalization: 11.296651714236775\n",
      "Validation accuracy: punctuation: 95.0649%, capitalization: 98.6356%\n",
      "Find a new best model!\n",
      "----------------------------\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 35.82704979669307\n",
      "Training loss for capitalization: 10.600434648452673\n",
      "Validation accuracy: punctuation: 95.1474%, capitalization: 98.5971%\n",
      "Find a new best model!\n",
      "----------------------------\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 34.682677963735706\n",
      "Training loss for capitalization: 9.953904759904908\n",
      "Validation accuracy: punctuation: 95.219%, capitalization: 98.5365%\n",
      "Find a new best model!\n",
      "----------------------------\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 33.683906736013626\n",
      "Training loss for capitalization: 9.38069772382142\n",
      "Validation accuracy: punctuation: 95.1529%, capitalization: 98.5585%\n",
      "----------------------------\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 32.76949356093961\n",
      "Training loss for capitalization: 8.848108127943194\n",
      "Validation accuracy: punctuation: 95.0264%, capitalization: 98.5585%\n",
      "----------------------------\n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 31.838123109294056\n",
      "Training loss for capitalization: 8.352086054951098\n",
      "Validation accuracy: punctuation: 95.0319%, capitalization: 98.553%\n",
      "----------------------------\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 31.029941956330692\n",
      "Training loss for capitalization: 7.913224732281793\n",
      "Validation accuracy: punctuation: 95.1419%, capitalization: 98.52%\n",
      "----------------------------\n",
      "Epoch: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13606.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss for punctuation: 30.289371945587096\n",
      "Training loss for capitalization: 7.482485956459138\n",
      "Validation accuracy: punctuation: 95.1695%, capitalization: 98.6026%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    best_model = train(train_loader, dev_loader, model, criterions, optimizer, 100, device)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1269: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: punctuation: 95.2895%, capitalization: 98.6305%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted correctly</th>\n",
       "      <th>predicted expectation</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punctuation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>o</td>\n",
       "      <td>19277</td>\n",
       "      <td>18722</td>\n",
       "      <td>19042</td>\n",
       "      <td>0.971159</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.977114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>1174</td>\n",
       "      <td>826</td>\n",
       "      <td>1354</td>\n",
       "      <td>0.702979</td>\n",
       "      <td>0.609594</td>\n",
       "      <td>0.652964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>1288</td>\n",
       "      <td>1172</td>\n",
       "      <td>1223</td>\n",
       "      <td>0.909232</td>\n",
       "      <td>0.957516</td>\n",
       "      <td>0.932750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.198675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             predicted  predicted correctly  predicted expectation  precision  \\\n",
       "punctuation                                                                     \n",
       "o                19277                18722                  19042   0.971159   \n",
       ",                 1174                  826                   1354   0.702979   \n",
       ".                 1288                 1172                   1223   0.909232   \n",
       "?                   21                   15                    128   0.681818   \n",
       "!                    0                    0                     13   0.000000   \n",
       "\n",
       "               recall   f_score  \n",
       "punctuation                      \n",
       "o            0.983143  0.977114  \n",
       ",            0.609594  0.652964  \n",
       ".            0.957516  0.932750  \n",
       "?            0.116279  0.198675  \n",
       "!            0.000000  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted correctly</th>\n",
       "      <th>predicted expectation</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capitalization</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No</td>\n",
       "      <td>19299</td>\n",
       "      <td>19101</td>\n",
       "      <td>19201</td>\n",
       "      <td>0.989689</td>\n",
       "      <td>0.994740</td>\n",
       "      <td>0.992208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yes</td>\n",
       "      <td>2461</td>\n",
       "      <td>2361</td>\n",
       "      <td>2559</td>\n",
       "      <td>0.958976</td>\n",
       "      <td>0.922266</td>\n",
       "      <td>0.940263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted  predicted correctly  predicted expectation  \\\n",
       "capitalization                                                          \n",
       "No                  19299                19101                  19201   \n",
       "Yes                  2461                 2361                   2559   \n",
       "\n",
       "                precision    recall   f_score  \n",
       "capitalization                                 \n",
       "No               0.989689  0.994740  0.992208  \n",
       "Yes              0.958976  0.922266  0.940263  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = test(test_loader, best_model, device)\n",
    "display(dfs[0])\n",
    "display(dfs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
